# çºªå½•ç‰‡è„šæœ¬ç”Ÿæˆ
import os
import json
import time
import asyncio
import traceback
import streamlit as st
from loguru import logger
from datetime import datetime

from app.config import config
from app.utils import utils, video_processor
from webui.tools.base import create_vision_analyzer, get_batch_files, get_batch_timestamps, chekc_video_config


def generate_script_docu(params):
    """
    ç”Ÿæˆ çºªå½•ç‰‡ è§†é¢‘è„šæœ¬
    è¦æ±‚: åŸè§†é¢‘æ— å­—å¹•æ— é…éŸ³
    é€‚åˆåœºæ™¯: çºªå½•ç‰‡ã€åŠ¨ç‰©æç¬‘è§£è¯´ã€è’é‡å»ºé€ ç­‰
    """
    progress_bar = st.progress(0)
    status_text = st.empty()

    def update_progress(progress: float, message: str = ""):
        progress_bar.progress(progress)
        if message:
            status_text.text(f"ğŸ¬ {message}")
        else:
            status_text.text(f"ğŸ“Š è¿›åº¦: {progress}%")

    try:
        with st.spinner("æ­£åœ¨ç”Ÿæˆè„šæœ¬..."):
            if not params.video_origin_path:
                st.error("è¯·å…ˆé€‰æ‹©è§†é¢‘æ–‡ä»¶")
                return
            """
            1. æå–é”®å¸§
            """
            update_progress(10, "æ­£åœ¨æå–å…³é”®å¸§...")

            # åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºå­˜å‚¨å…³é”®å¸§
            keyframes_dir = os.path.join(utils.temp_dir(), "keyframes")
            video_hash = utils.md5(params.video_origin_path + str(os.path.getmtime(params.video_origin_path)))
            video_keyframes_dir = os.path.join(keyframes_dir, video_hash)

            # æ£€æŸ¥æ˜¯å¦å·²ç»æå–è¿‡å…³é”®å¸§
            keyframe_files = []
            if os.path.exists(video_keyframes_dir):
                # å–å·²æœ‰çš„å…³é”®å¸§æ–‡ä»¶
                for filename in sorted(os.listdir(video_keyframes_dir)):
                    if filename.endswith('.jpg'):
                        keyframe_files.append(os.path.join(video_keyframes_dir, filename))

                if keyframe_files:
                    logger.info(f"ä½¿ç”¨å·²ç¼“å­˜çš„å…³é”®å¸§: {video_keyframes_dir}")
                    st.info(f"âœ… ä½¿ç”¨å·²ç¼“å­˜å…³é”®å¸§ï¼Œå…± {len(keyframe_files)} å¸§")
                    update_progress(20, f"ä½¿ç”¨å·²ç¼“å­˜å…³é”®å¸§ï¼Œå…± {len(keyframe_files)} å¸§")

            # å¦‚æœæ²¡æœ‰ç¼“å­˜çš„å…³é”®å¸§ï¼Œåˆ™è¿›è¡Œæå–
            if not keyframe_files:
                try:
                    # ç¡®ä¿ç›®å½•å­˜åœ¨
                    os.makedirs(video_keyframes_dir, exist_ok=True)

                    # åˆå§‹åŒ–è§†é¢‘å¤„ç†å™¨
                    processor = video_processor.VideoProcessor(params.video_origin_path)

                    # æ˜¾ç¤ºè§†é¢‘ä¿¡æ¯
                    st.info(f"ğŸ“¹ è§†é¢‘ä¿¡æ¯: {processor.width}x{processor.height}, {processor.fps:.1f}fps, {processor.duration:.1f}ç§’")

                    # å¤„ç†è§†é¢‘å¹¶æå–å…³é”®å¸§ - ç›´æ¥ä½¿ç”¨è¶…çº§å…¼å®¹æ€§æ–¹æ¡ˆ
                    update_progress(15, "æ­£åœ¨æå–å…³é”®å¸§ï¼ˆä½¿ç”¨è¶…çº§å…¼å®¹æ€§æ–¹æ¡ˆï¼‰...")

                    try:
                        # ä½¿ç”¨ä¼˜åŒ–çš„å…³é”®å¸§æå–æ–¹æ³•
                        processor.extract_frames_by_interval_ultra_compatible(
                            output_dir=video_keyframes_dir,
                            interval_seconds=st.session_state.get('frame_interval_input'),
                        )
                    except Exception as extract_error:
                        logger.error(f"å…³é”®å¸§æå–å¤±è´¥: {extract_error}")
                        
                        # æä¾›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯å’Œè§£å†³å»ºè®®
                        error_msg = str(extract_error)
                        if "æƒé™" in error_msg or "permission" in error_msg.lower():
                            suggestion = "å»ºè®®ï¼šæ£€æŸ¥è¾“å‡ºç›®å½•æƒé™ï¼Œæˆ–æ›´æ¢è¾“å‡ºä½ç½®"
                        elif "ç©ºé—´" in error_msg or "space" in error_msg.lower():
                            suggestion = "å»ºè®®ï¼šæ£€æŸ¥ç£ç›˜ç©ºé—´æ˜¯å¦è¶³å¤Ÿ"
                        else:
                            suggestion = "å»ºè®®ï¼šæ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦æŸåï¼Œæˆ–å°è¯•è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼"

                        raise Exception(f"å…³é”®å¸§æå–å¤±è´¥: {error_msg}\n{suggestion}")

                    # è·å–æ‰€æœ‰å…³é”®æ–‡ä»¶è·¯å¾„
                    for filename in sorted(os.listdir(video_keyframes_dir)):
                        if filename.endswith('.jpg'):
                            keyframe_files.append(os.path.join(video_keyframes_dir, filename))

                    if not keyframe_files:
                        # æ£€æŸ¥ç›®å½•ä¸­æ˜¯å¦æœ‰å…¶ä»–æ–‡ä»¶
                        all_files = os.listdir(video_keyframes_dir)
                        logger.error(f"å…³é”®å¸§ç›®å½•å†…å®¹: {all_files}")
                        raise Exception("æœªæå–åˆ°ä»»ä½•å…³é”®å¸§æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ ¼å¼")

                    update_progress(20, f"å…³é”®å¸§æå–å®Œæˆï¼Œå…± {len(keyframe_files)} å¸§")
                    st.success(f"âœ… æˆåŠŸæå– {len(keyframe_files)} ä¸ªå…³é”®å¸§")

                except Exception as e:
                    # å¦‚æœæå–å¤±è´¥ï¼Œæ¸…ç†åˆ›å»ºçš„ç›®å½•
                    try:
                        if os.path.exists(video_keyframes_dir):
                            import shutil
                            shutil.rmtree(video_keyframes_dir)
                    except Exception as cleanup_err:
                        logger.error(f"æ¸…ç†å¤±è´¥çš„å…³é”®å¸§ç›®å½•æ—¶å‡ºé”™: {cleanup_err}")

                    raise Exception(f"å…³é”®å¸§æå–å¤±è´¥: {str(e)}")

            """
            2. è§†è§‰åˆ†æ(æ‰¹é‡åˆ†ææ¯ä¸€å¸§)
            """
            # æœ€ä½³å®è·µï¼šä½¿ç”¨ get() çš„é»˜è®¤å€¼å‚æ•° + ä» config è·å–å¤‡ç”¨å€¼
            vision_llm_provider = (
                st.session_state.get('vision_llm_provider') or
                config.app.get('vision_llm_provider', 'litellm')
            ).lower()

            logger.info(f"ä½¿ç”¨ {vision_llm_provider.upper()} è¿›è¡Œè§†è§‰åˆ†æ")

            try:
                # ===================åˆå§‹åŒ–è§†è§‰åˆ†æå™¨===================
                update_progress(30, "æ­£åœ¨åˆå§‹åŒ–è§†è§‰åˆ†æå™¨...")

                # ä½¿ç”¨ç»Ÿä¸€çš„é…ç½®é”®æ ¼å¼è·å–é…ç½®ï¼ˆæ”¯æŒæ‰€æœ‰ providerï¼‰
                vision_api_key = (
                    st.session_state.get(f'vision_{vision_llm_provider}_api_key') or
                    config.app.get(f'vision_{vision_llm_provider}_api_key')
                )
                vision_model = (
                    st.session_state.get(f'vision_{vision_llm_provider}_model_name') or
                    config.app.get(f'vision_{vision_llm_provider}_model_name')
                )
                vision_base_url = (
                    st.session_state.get(f'vision_{vision_llm_provider}_base_url') or
                    config.app.get(f'vision_{vision_llm_provider}_base_url', '')
                )

                # éªŒè¯å¿…éœ€é…ç½®
                if not vision_api_key or not vision_model:
                    raise ValueError(
                        f"æœªé…ç½® {vision_llm_provider} çš„ API Key æˆ–æ¨¡å‹åç§°ã€‚"
                        f"è¯·åœ¨è®¾ç½®é¡µé¢é…ç½® vision_{vision_llm_provider}_api_key å’Œ vision_{vision_llm_provider}_model_name"
                    )

                # åˆ›å»ºè§†è§‰åˆ†æå™¨å®ä¾‹ï¼ˆä½¿ç”¨ç»Ÿä¸€æ¥å£ï¼‰
                llm_params = {
                    "vision_provider": vision_llm_provider,
                    "vision_api_key": vision_api_key,
                    "vision_model_name": vision_model,
                    "vision_base_url": vision_base_url,
                }

                logger.debug(f"è§†è§‰åˆ†æå™¨é…ç½®: provider={vision_llm_provider}, model={vision_model}")

                analyzer = create_vision_analyzer(
                    provider=vision_llm_provider,
                    api_key=vision_api_key,
                    model=vision_model,
                    base_url=vision_base_url
                )

                update_progress(40, "æ­£åœ¨åˆ†æå…³é”®å¸§...")

                # ===================åˆ›å»ºå¼‚æ­¥äº‹ä»¶å¾ªç¯===================
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)

                # æ‰§è¡Œå¼‚æ­¥åˆ†æ
                vision_batch_size = st.session_state.get('vision_batch_size') or config.frames.get("vision_batch_size")
                vision_analysis_prompt = """
æˆ‘æä¾›äº† %s å¼ è§†é¢‘å¸§ï¼Œå®ƒä»¬æŒ‰æ—¶é—´é¡ºåºæ’åˆ—ï¼Œä»£è¡¨ä¸€ä¸ªè¿ç»­çš„è§†é¢‘ç‰‡æ®µã€‚è¯·ä»”ç»†åˆ†ææ¯ä¸€å¸§çš„å†…å®¹ï¼Œå¹¶å…³æ³¨å¸§ä¸å¸§ä¹‹é—´çš„å˜åŒ–ï¼Œä»¥ç†è§£æ•´ä¸ªç‰‡æ®µçš„æ´»åŠ¨ã€‚

é¦–å…ˆï¼Œè¯·è¯¦ç»†æè¿°æ¯ä¸€å¸§çš„å…³é”®è§†è§‰ä¿¡æ¯ï¼ˆåŒ…å«ï¼šä¸»è¦å†…å®¹ã€äººç‰©ã€åŠ¨ä½œå’Œåœºæ™¯ï¼‰ã€‚
ç„¶åï¼ŒåŸºäºæ‰€æœ‰å¸§çš„åˆ†æï¼Œè¯·ç”¨**ç®€æ´çš„è¯­è¨€**æ€»ç»“æ•´ä¸ªè§†é¢‘ç‰‡æ®µä¸­å‘ç”Ÿçš„ä¸»è¦æ´»åŠ¨æˆ–äº‹ä»¶æµç¨‹ã€‚

è¯·åŠ¡å¿…ä½¿ç”¨ JSON æ ¼å¼è¾“å‡ºä½ çš„ç»“æœã€‚JSON ç»“æ„åº”å¦‚ä¸‹ï¼š
{
  "frame_observations": [
    {
      "frame_number": 1, // æˆ–å…¶ä»–æ ‡è¯†å¸§çš„æ–¹å¼
      "observation": "æè¿°æ¯å¼ è§†é¢‘å¸§ä¸­çš„ä¸»è¦å†…å®¹ã€äººç‰©ã€åŠ¨ä½œå’Œåœºæ™¯ã€‚"
    },
    // ... æ›´å¤šå¸§çš„è§‚å¯Ÿ ...
  ],
  "overall_activity_summary": "åœ¨è¿™é‡Œå¡«å†™ä½ æ€»ç»“çš„æ•´ä¸ªç‰‡æ®µçš„ä¸»è¦æ´»åŠ¨ï¼Œä¿æŒç®€æ´ã€‚"
}

è¯·åŠ¡å¿…ä¸è¦é—æ¼è§†é¢‘å¸§ï¼Œæˆ‘æä¾›äº† %s å¼ è§†é¢‘å¸§ï¼Œframe_observations å¿…é¡»åŒ…å« %s ä¸ªå…ƒç´ 

è¯·åªè¿”å› JSON å­—ç¬¦ä¸²ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–è§£é‡Šæ€§æ–‡å­—ã€‚
                """
                results = loop.run_until_complete(
                    analyzer.analyze_images(
                        images=keyframe_files,
                        prompt=vision_analysis_prompt,
                        batch_size=vision_batch_size
                    )
                )
                loop.close()

                """
                3. å¤„ç†åˆ†æç»“æœï¼ˆæ ¼å¼åŒ–ä¸º json æ•°æ®ï¼‰
                """
                # ===================å¤„ç†åˆ†æç»“æœ===================
                update_progress(60, "æ­£åœ¨æ•´ç†åˆ†æç»“æœ...")

                # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡çš„åˆ†æç»“æœ
                frame_analysis = ""
                merged_frame_observations = []  # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡çš„å¸§è§‚å¯Ÿ
                overall_activity_summaries = []  # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡çš„æ•´ä½“æ€»ç»“
                prev_batch_files = None
                frame_counter = 1  # åˆå§‹åŒ–å¸§è®¡æ•°å™¨ï¼Œç”¨äºç»™æ‰€æœ‰å¸§åˆ†é…è¿ç»­çš„åºå·
                
                # ç¡®ä¿åˆ†æç›®å½•å­˜åœ¨
                analysis_dir = os.path.join(utils.storage_dir(), "temp", "analysis")
                os.makedirs(analysis_dir, exist_ok=True)
                origin_res = os.path.join(analysis_dir, "frame_analysis.json")
                with open(origin_res, 'w', encoding='utf-8') as f:
                    json.dump(results, f, ensure_ascii=False, indent=2)
                
                # å¼€å§‹å¤„ç†
                for result in results:
                    if 'error' in result:
                        logger.warning(f"æ‰¹æ¬¡ {result['batch_index']} å¤„ç†å‡ºç°è­¦å‘Š: {result['error']}")
                        continue
                        
                    # è·å–å½“å‰æ‰¹æ¬¡çš„æ–‡ä»¶åˆ—è¡¨
                    batch_files = get_batch_files(keyframe_files, result, vision_batch_size)
                    
                    # è·å–æ‰¹æ¬¡çš„æ—¶é—´æˆ³èŒƒå›´
                    first_timestamp, last_timestamp, timestamp_range = get_batch_timestamps(batch_files, prev_batch_files)
                    
                    # è§£æå“åº”ä¸­çš„JSONæ•°æ®
                    response_text = result['response']
                    try:
                        # å¤„ç†å¯èƒ½åŒ…å«```json```æ ¼å¼çš„å“åº”
                        if "```json" in response_text:
                            json_content = response_text.split("```json")[1].split("```")[0].strip()
                        elif "```" in response_text:
                            json_content = response_text.split("```")[1].split("```")[0].strip()
                        else:
                            json_content = response_text.strip()
                            
                        response_data = json.loads(json_content)
                        
                        # æå–frame_observationså’Œoverall_activity_summary
                        if "frame_observations" in response_data:
                            frame_obs = response_data["frame_observations"]
                            overall_summary = response_data.get("overall_activity_summary", "")
                            
                            # æ·»åŠ æ—¶é—´æˆ³ä¿¡æ¯åˆ°æ¯ä¸ªå¸§è§‚å¯Ÿ
                            for i, obs in enumerate(frame_obs):
                                if i < len(batch_files):
                                    # ä»æ–‡ä»¶åä¸­æå–æ—¶é—´æˆ³
                                    file_path = batch_files[i]
                                    file_name = os.path.basename(file_path)
                                    # æå–æ—¶é—´æˆ³å­—ç¬¦ä¸² (æ ¼å¼å¦‚: keyframe_000675_000027000.jpg)
                                    # æ ¼å¼è§£æ: keyframe_å¸§åºå·_æ¯«ç§’æ—¶é—´æˆ³.jpg
                                    timestamp_parts = file_name.split('_')
                                    if len(timestamp_parts) >= 3:
                                        timestamp_str = timestamp_parts[-1].split('.')[0]
                                        try:
                                            # ä¿®æ­£æ—¶é—´æˆ³è§£æé€»è¾‘
                                            # æ ¼å¼ä¸º000100000ï¼Œè¡¨ç¤º00:01:00,000ï¼Œå³1åˆ†é’Ÿ
                                            # éœ€è¦æŒ‰ç…§å¯¹åº”ä½æ•°è¿›è¡Œè§£æ:
                                            # å‰ä¸¤ä½æ˜¯å°æ—¶ï¼Œä¸­é—´ä¸¤ä½æ˜¯åˆ†é’Ÿï¼Œåé¢æ˜¯ç§’å’Œæ¯«ç§’
                                            if len(timestamp_str) >= 9:  # ç¡®ä¿æ ¼å¼æ­£ç¡®
                                                hours = int(timestamp_str[0:2])
                                                minutes = int(timestamp_str[2:4])
                                                seconds = int(timestamp_str[4:6])
                                                milliseconds = int(timestamp_str[6:9])
                                                
                                                # è®¡ç®—æ€»ç§’æ•°
                                                timestamp_seconds = hours * 3600 + minutes * 60 + seconds + milliseconds / 1000
                                                formatted_time = utils.format_time(timestamp_seconds)  # æ ¼å¼åŒ–æ—¶é—´æˆ³
                                            else:
                                                # å…¼å®¹æ—§çš„è§£ææ–¹å¼
                                                timestamp_seconds = int(timestamp_str) / 1000  # è½¬æ¢ä¸ºç§’
                                                formatted_time = utils.format_time(timestamp_seconds)  # æ ¼å¼åŒ–æ—¶é—´æˆ³
                                        except ValueError:
                                            logger.warning(f"æ— æ³•è§£ææ—¶é—´æˆ³: {timestamp_str}")
                                            timestamp_seconds = 0
                                            formatted_time = "00:00:00,000"
                                    else:
                                        logger.warning(f"æ–‡ä»¶åæ ¼å¼ä¸ç¬¦åˆé¢„æœŸ: {file_name}")
                                        timestamp_seconds = 0
                                        formatted_time = "00:00:00,000"
                                    
                                    # æ·»åŠ é¢å¤–ä¿¡æ¯åˆ°å¸§è§‚å¯Ÿ
                                    obs["frame_path"] = file_path
                                    obs["timestamp"] = formatted_time
                                    obs["timestamp_seconds"] = timestamp_seconds
                                    obs["batch_index"] = result['batch_index']
                                    
                                    # ä½¿ç”¨å…¨å±€é€’å¢çš„å¸§è®¡æ•°å™¨æ›¿æ¢åŸå§‹çš„frame_number
                                    if "frame_number" in obs:
                                        obs["original_frame_number"] = obs["frame_number"]  # ä¿ç•™åŸå§‹ç¼–å·ä½œä¸ºå‚è€ƒ
                                    obs["frame_number"] = frame_counter  # èµ‹å€¼è¿ç»­çš„å¸§ç¼–å·
                                    frame_counter += 1  # å¢åŠ å¸§è®¡æ•°å™¨
                                    
                                    # æ·»åŠ åˆ°åˆå¹¶åˆ—è¡¨
                                    merged_frame_observations.append(obs)
                            
                            # æ·»åŠ æ‰¹æ¬¡æ•´ä½“æ€»ç»“ä¿¡æ¯
                            if overall_summary:
                                # ä»æ–‡ä»¶åä¸­æå–æ—¶é—´æˆ³æ•°å€¼
                                first_time_str = first_timestamp.split('_')[-1].split('.')[0]
                                last_time_str = last_timestamp.split('_')[-1].split('.')[0]
                                
                                # è½¬æ¢ä¸ºæ¯«ç§’å¹¶è®¡ç®—æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
                                try:
                                    # ä¿®æ­£è§£æé€»è¾‘ï¼Œä¸ä¸Šé¢ç›¸åŒçš„æ–¹å¼è§£ææ—¶é—´æˆ³
                                    if len(first_time_str) >= 9 and len(last_time_str) >= 9:
                                        # è§£æç¬¬ä¸€ä¸ªæ—¶é—´æˆ³
                                        first_hours = int(first_time_str[0:2])
                                        first_minutes = int(first_time_str[2:4])
                                        first_seconds = int(first_time_str[4:6])
                                        first_ms = int(first_time_str[6:9])
                                        first_time_seconds = first_hours * 3600 + first_minutes * 60 + first_seconds + first_ms / 1000
                                        
                                        # è§£æç¬¬äºŒä¸ªæ—¶é—´æˆ³
                                        last_hours = int(last_time_str[0:2])
                                        last_minutes = int(last_time_str[2:4])
                                        last_seconds = int(last_time_str[4:6])
                                        last_ms = int(last_time_str[6:9])
                                        last_time_seconds = last_hours * 3600 + last_minutes * 60 + last_seconds + last_ms / 1000
                                        
                                        batch_duration = last_time_seconds - first_time_seconds
                                    else:
                                        # å…¼å®¹æ—§çš„è§£ææ–¹å¼
                                        first_time_ms = int(first_time_str)
                                        last_time_ms = int(last_time_str)
                                        batch_duration = (last_time_ms - first_time_ms) / 1000
                                except ValueError:
                                    # ä½¿ç”¨ utils.time_to_seconds å‡½æ•°å¤„ç†æ ¼å¼åŒ–çš„æ—¶é—´æˆ³
                                    first_time_seconds = utils.time_to_seconds(first_time_str.replace('_', ':').replace('-', ','))
                                    last_time_seconds = utils.time_to_seconds(last_time_str.replace('_', ':').replace('-', ','))
                                    batch_duration = last_time_seconds - first_time_seconds
                                
                                overall_activity_summaries.append({
                                    "batch_index": result['batch_index'],
                                    "time_range": f"{first_timestamp}-{last_timestamp}",
                                    "duration_seconds": batch_duration,
                                    "summary": overall_summary
                                })
                    except Exception as e:
                        logger.error(f"è§£ææ‰¹æ¬¡ {result['batch_index']} çš„å“åº”æ•°æ®å¤±è´¥: {str(e)}")
                        # æ·»åŠ åŸå§‹å“åº”ä½œä¸ºå›é€€
                        frame_analysis += f"\n=== {first_timestamp}-{last_timestamp} ===\n"
                        frame_analysis += response_text
                        frame_analysis += "\n"
                    
                    # æ›´æ–°ä¸Šä¸€ä¸ªæ‰¹æ¬¡çš„æ–‡ä»¶
                    prev_batch_files = batch_files
                
                # å°†åˆå¹¶åçš„ç»“æœè½¬ä¸ºJSONå­—ç¬¦ä¸²
                merged_results = {
                    "frame_observations": merged_frame_observations,
                    "overall_activity_summaries": overall_activity_summaries
                }
                
                # ä½¿ç”¨å½“å‰æ—¶é—´åˆ›å»ºæ–‡ä»¶å
                now = datetime.now()
                timestamp_str = now.strftime("%Y%m%d_%H%M")
                
                # ä¿å­˜å®Œæ•´çš„åˆ†æç»“æœä¸ºJSON
                analysis_filename = f"frame_analysis_{timestamp_str}.json"
                analysis_json_path = os.path.join(analysis_dir, analysis_filename)
                with open(analysis_json_path, 'w', encoding='utf-8') as f:
                    json.dump(merged_results, f, ensure_ascii=False, indent=2)
                logger.info(f"åˆ†æç»“æœå·²ä¿å­˜åˆ°: {analysis_json_path}")

                """
                4. ç”Ÿæˆæ–‡æ¡ˆ
                """
                logger.info("å¼€å§‹ç”Ÿæˆè§£è¯´æ–‡æ¡ˆ")
                update_progress(80, "æ­£åœ¨ç”Ÿæˆè§£è¯´æ–‡æ¡ˆ...")
                from app.services.generate_narration_script import parse_frame_analysis_to_markdown, generate_narration
                # ä»é…ç½®ä¸­è·å–æ–‡æœ¬ç”Ÿæˆç›¸å…³é…ç½®
                text_provider = config.app.get('text_llm_provider', 'gemini').lower()
                text_api_key = config.app.get(f'text_{text_provider}_api_key')
                text_model = config.app.get(f'text_{text_provider}_model_name')
                text_base_url = config.app.get(f'text_{text_provider}_base_url')
                llm_params.update({
                    "text_provider": text_provider,
                    "text_api_key": text_api_key,
                    "text_model_name": text_model,
                    "text_base_url": text_base_url
                })
                chekc_video_config(llm_params)
                # æ•´ç†å¸§åˆ†ææ•°æ®
                markdown_output = parse_frame_analysis_to_markdown(analysis_json_path)

                # ç”Ÿæˆè§£è¯´æ–‡æ¡ˆ
                narration = generate_narration(
                    markdown_output,
                    text_api_key,
                    base_url=text_base_url,
                    model=text_model
                )

                # ä½¿ç”¨å¢å¼ºçš„JSONè§£æå™¨
                from webui.tools.generate_short_summary import parse_and_fix_json
                narration_data = parse_and_fix_json(narration)

                if not narration_data or 'items' not in narration_data:
                    logger.error(f"è§£è¯´æ–‡æ¡ˆJSONè§£æå¤±è´¥ï¼ŒåŸå§‹å†…å®¹: {narration[:200]}...")
                    raise Exception("è§£è¯´æ–‡æ¡ˆæ ¼å¼é”™è¯¯ï¼Œæ— æ³•è§£æJSONæˆ–ç¼ºå°‘itemså­—æ®µ")

                narration_dict = narration_data['items']
                # ä¸º narration_dict ä¸­æ¯ä¸ª item æ–°å¢ä¸€ä¸ª OST: 2 çš„å­—æ®µ, ä»£è¡¨ä¿ç•™åŸå£°å’Œé…éŸ³
                narration_dict = [{**item, "OST": 2} for item in narration_dict]
                logger.info(f"è§£è¯´æ–‡æ¡ˆç”Ÿæˆå®Œæˆï¼Œå…± {len(narration_dict)} ä¸ªç‰‡æ®µ")
                # ç»“æœè½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
                script = json.dumps(narration_dict, ensure_ascii=False, indent=2)

            except Exception as e:
                logger.exception(f"å¤§æ¨¡å‹å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯\n{traceback.format_exc()}")
                raise Exception(f"åˆ†æå¤±è´¥: {str(e)}")

            if script is None:
                st.error("ç”Ÿæˆè„šæœ¬å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
                st.stop()
            logger.info(f"çºªå½•ç‰‡è§£è¯´è„šæœ¬ç”Ÿæˆå®Œæˆ")
            if isinstance(script, list):
                st.session_state['video_clip_json'] = script
            elif isinstance(script, str):
                st.session_state['video_clip_json'] = json.loads(script)
            update_progress(100, "è„šæœ¬ç”Ÿæˆå®Œæˆ")

        time.sleep(0.1)
        progress_bar.progress(100)
        status_text.text("ğŸ‰ è„šæœ¬ç”Ÿæˆå®Œæˆï¼")
        st.success("âœ… è§†é¢‘è„šæœ¬ç”ŸæˆæˆåŠŸï¼")

    except Exception as err:
        st.error(f"âŒ ç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(err)}")
        logger.exception(f"ç”Ÿæˆè„šæœ¬æ—¶å‘ç”Ÿé”™è¯¯\n{traceback.format_exc()}")
    finally:
        time.sleep(2)
        progress_bar.empty()
        status_text.empty()
